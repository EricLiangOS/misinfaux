{"ast":null,"code":"import React from'react';import{jsx as _jsx,jsxs as _jsxs}from\"react/jsx-runtime\";const SummaryModal=_ref=>{var _results$problematicE,_results$problematicE2,_results$problematicE3,_results$problematicE4;let{isOpen,onClose,results}=_ref;if(!isOpen||!results)return null;const{textMetrics,entropyScore,klDivergence}=results;const overusedWordsCount=((_results$problematicE=results.problematicElements)===null||_results$problematicE===void 0?void 0:(_results$problematicE2=_results$problematicE.overusedWords)===null||_results$problematicE2===void 0?void 0:_results$problematicE2.length)||0;const suspiciousWordsCount=((_results$problematicE3=results.problematicElements)===null||_results$problematicE3===void 0?void 0:(_results$problematicE4=_results$problematicE3.suspiciousWords)===null||_results$problematicE4===void 0?void 0:_results$problematicE4.length)||0;// Calculate sentence length score as in the model\nconst avgSentenceLength=textMetrics.avgSentenceLength;const sentenceLengthScore=Math.abs(avgSentenceLength-17.5)/10;// Calculate the logistic regression formula result\n// For P(misleading) = 1/(1 + e^-(intercept + β₁*x₁ + β₂*x₂ + ... + βₙxₙ))\nconst intercept=1.217970;const weights={entropy:0.600971,// Changed from -1.0\nklDivergence:-1.847155,// Changed from 2.0\noverusedWords:-1.318058,// Changed from 3.0\nsuspiciousWords:-1.026311,// Changed from 1.5\nsentenceLength:-2.889868// Changed from -0.5\n};const logitScore=intercept+weights.entropy*entropyScore+weights.klDivergence*klDivergence+weights.overusedWords*overusedWordsCount/10+weights.suspiciousWords*suspiciousWordsCount+weights.sentenceLength*sentenceLengthScore;// Calculate probability: P = 1/(1 + e^-z)\nconst reliabilityProbability=1/(1+Math.exp(-logitScore));const probabilityPercentage=(reliabilityProbability*100).toFixed(1);// Calculate confidence based on absolute value of z-score\nconst absLogit=Math.abs(logitScore);const confidence=Math.min(0.99,0.5+0.1*absLogit);const confidencePercentage=(confidence*100).toFixed(1);// Determine classification: reliable when z >= 0 (probability >= 50%)\nconst isReliable=logitScore>=0;const classification=isReliable?\"Likely Reliable\":\"Potentially Misleading\";return/*#__PURE__*/_jsx(\"div\",{className:\"modal-overlay\",children:/*#__PURE__*/_jsxs(\"div\",{className:\"modal-content\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"modal-header\",children:[/*#__PURE__*/_jsx(\"h2\",{children:\"Text Metrics\"}),/*#__PURE__*/_jsx(\"button\",{className:\"close-btn\",onClick:onClose,children:\"\\xD7\"})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"modal-body\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"metrics-summary\",children:[/*#__PURE__*/_jsxs(\"div\",{className:\"metric-item\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Text Structure\"}),/*#__PURE__*/_jsxs(\"ul\",{children:[/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Word Count:\"}),\" \",textMetrics.wordCount]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Unique Words:\"}),\" \",textMetrics.uniqueWordCount]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Lexical Diversity:\"}),\" \",(textMetrics.uniqueWordCount/textMetrics.wordCount).toFixed(2)]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Sentence Count:\"}),\" \",textMetrics.sentenceCount]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Avg. Sentence Length:\"}),\" \",textMetrics.avgSentenceLength,\" words\"]})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"metric-item\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Information Theory\"}),/*#__PURE__*/_jsxs(\"ul\",{children:[/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Shannon Entropy:\"}),\" \",entropyScore]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"KL Divergence:\"}),\" \",klDivergence]})]}),/*#__PURE__*/_jsx(\"p\",{className:\"metric-explanation\",children:\"Shannon entropy measures the information content of the text. Higher values indicate more diverse vocabulary. KL divergence measures how the word distribution differs from typical reliable sources.\"})]})]}),/*#__PURE__*/_jsxs(\"div\",{className:\"classification-calculation\",children:[/*#__PURE__*/_jsx(\"h3\",{children:\"Classification Calculation\"}),/*#__PURE__*/_jsx(\"p\",{children:\"Our logistic regression model uses the following formula to determine the probability of misinformation:\"}),/*#__PURE__*/_jsx(\"div\",{className:\"formula\",children:/*#__PURE__*/_jsxs(\"span\",{children:[\"P(misleading) = 1/(1 + e\",/*#__PURE__*/_jsx(\"sup\",{children:\"-z\"}),\")\"]})}),/*#__PURE__*/_jsx(\"p\",{children:\"Where z = 1.22 + (0.80 \\xD7 Entropy) + (-1.85 \\xD7 KL Divergence) + (-1.32 \\xD7 Overused Words/10) + (-3.03 \\xD7 Suspicious Words) + (2.89 \\xD7 Sentence Length Score)\"}),/*#__PURE__*/_jsxs(\"div\",{className:\"calculation-details\",children:[/*#__PURE__*/_jsx(\"p\",{children:\"For this article:\"}),/*#__PURE__*/_jsxs(\"ul\",{children:[/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Entropy:\"}),\" \",entropyScore,\" \\xD7 \",weights.entropy,\" = \",(entropyScore*weights.entropy).toFixed(2)]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"KL Divergence:\"}),\" \",klDivergence,\" \\xD7 \",weights.klDivergence,\" = \",(klDivergence*weights.klDivergence).toFixed(2)]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Overused Words:\"}),\" \",overusedWordsCount,\"/10 \\xD7 \",weights.overusedWords,\" = \",(overusedWordsCount/10*weights.overusedWords).toFixed(2)]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Suspicious Words:\"}),\" \",suspiciousWordsCount,\" \\xD7 \",weights.suspiciousWords,\" = \",(suspiciousWordsCount*weights.suspiciousWords).toFixed(2)]}),/*#__PURE__*/_jsxs(\"li\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Sentence Length Score:\"}),\" \",sentenceLengthScore.toFixed(2),\" \\xD7 \",weights.sentenceLength,\" = \",(sentenceLengthScore*weights.sentenceLength).toFixed(2)]})]}),/*#__PURE__*/_jsx(\"p\",{children:/*#__PURE__*/_jsxs(\"strong\",{children:[\"z = \",logitScore.toFixed(2)]})}),/*#__PURE__*/_jsx(\"p\",{children:/*#__PURE__*/_jsxs(\"strong\",{children:[\"Reliability Probability = \",probabilityPercentage,\"%\"]})}),/*#__PURE__*/_jsxs(\"p\",{children:[/*#__PURE__*/_jsx(\"strong\",{children:\"Confidence Level:\"}),\" \",confidencePercentage,\"% (based on the magnitude of z-score)\"]})]})]}),/*#__PURE__*/_jsx(\"div\",{className:\"modal-footer\",children:/*#__PURE__*/_jsx(\"p\",{children:\"For more detailed analysis and interactive visualizations, please refer to the Analysis Summary tab.\"})})]})]})});};export default SummaryModal;","map":{"version":3,"names":["React","jsx","_jsx","jsxs","_jsxs","SummaryModal","_ref","_results$problematicE","_results$problematicE2","_results$problematicE3","_results$problematicE4","isOpen","onClose","results","textMetrics","entropyScore","klDivergence","overusedWordsCount","problematicElements","overusedWords","length","suspiciousWordsCount","suspiciousWords","avgSentenceLength","sentenceLengthScore","Math","abs","intercept","weights","entropy","sentenceLength","logitScore","reliabilityProbability","exp","probabilityPercentage","toFixed","absLogit","confidence","min","confidencePercentage","isReliable","classification","className","children","onClick","wordCount","uniqueWordCount","sentenceCount"],"sources":["/Users/ehliang/Desktop/Projects/misinfaux/misinfaux/frontend/src/components/SummaryModal.js"],"sourcesContent":["import React from 'react';\n\nconst SummaryModal = ({ isOpen, onClose, results }) => {\n    if (!isOpen || !results) return null;\n    \n    const { textMetrics, entropyScore, klDivergence } = results;\n    const overusedWordsCount = results.problematicElements?.overusedWords?.length || 0;\n    const suspiciousWordsCount = results.problematicElements?.suspiciousWords?.length || 0;\n    \n    // Calculate sentence length score as in the model\n    const avgSentenceLength = textMetrics.avgSentenceLength;\n    const sentenceLengthScore = Math.abs(avgSentenceLength - 17.5) / 10;\n    \n    // Calculate the logistic regression formula result\n    // For P(misleading) = 1/(1 + e^-(intercept + β₁*x₁ + β₂*x₂ + ... + βₙxₙ))\n    const intercept = 1.217970;\n    const weights = {\n        entropy: 0.600971,        // Changed from -1.0\n        klDivergence: -1.847155,  // Changed from 2.0\n        overusedWords: -1.318058, // Changed from 3.0\n        suspiciousWords: -1.026311, // Changed from 1.5\n        sentenceLength: -2.889868   // Changed from -0.5\n    };\n    \n    const logitScore = intercept + \n    (weights.entropy * entropyScore) + \n    (weights.klDivergence * klDivergence) + \n    (weights.overusedWords * overusedWordsCount / 10) + \n    (weights.suspiciousWords * suspiciousWordsCount) + \n    (weights.sentenceLength * sentenceLengthScore);\n\n    // Calculate probability: P = 1/(1 + e^-z)\n    const reliabilityProbability = 1 / (1 + Math.exp(-logitScore));\n    const probabilityPercentage = (reliabilityProbability * 100).toFixed(1);\n    \n    // Calculate confidence based on absolute value of z-score\n    const absLogit = Math.abs(logitScore);\n    const confidence = Math.min(0.99, 0.5 + 0.1 * absLogit);\n    const confidencePercentage = (confidence * 100).toFixed(1);\n    \n    // Determine classification: reliable when z >= 0 (probability >= 50%)\n    const isReliable = logitScore >= 0;\n    const classification = isReliable ? \"Likely Reliable\" : \"Potentially Misleading\";\n\n    \n    return (\n        <div className=\"modal-overlay\">\n            <div className=\"modal-content\">\n                <div className=\"modal-header\">\n                    <h2>Text Metrics</h2>\n                    <button className=\"close-btn\" onClick={onClose}>×</button>\n                </div>\n                \n                <div className=\"modal-body\">\n                    <div className=\"metrics-summary\">\n                        <div className=\"metric-item\">\n                            <h3>Text Structure</h3>\n                            <ul>\n                                <li><strong>Word Count:</strong> {textMetrics.wordCount}</li>\n                                <li><strong>Unique Words:</strong> {textMetrics.uniqueWordCount}</li>\n                                <li><strong>Lexical Diversity:</strong> {(textMetrics.uniqueWordCount / textMetrics.wordCount).toFixed(2)}</li>\n                                <li><strong>Sentence Count:</strong> {textMetrics.sentenceCount}</li>\n                                <li><strong>Avg. Sentence Length:</strong> {textMetrics.avgSentenceLength} words</li>\n                            </ul>\n                        </div>\n                        \n                        <div className=\"metric-item\">\n                            <h3>Information Theory</h3>\n                            <ul>\n                                <li><strong>Shannon Entropy:</strong> {entropyScore}</li>\n                                <li><strong>KL Divergence:</strong> {klDivergence}</li>\n                            </ul>\n                            <p className=\"metric-explanation\">\n                                Shannon entropy measures the information content of the text. Higher values indicate more diverse vocabulary.\n                                KL divergence measures how the word distribution differs from typical reliable sources.\n                            </p>\n                        </div>\n                    </div>\n                    \n                    <div className=\"classification-calculation\">\n                        <h3>Classification Calculation</h3>\n                        <p>Our logistic regression model uses the following formula to determine the probability of misinformation:</p>\n                        <div className=\"formula\">\n                            <span>P(misleading) = 1/(1 + e<sup>-z</sup>)</span>\n                        </div>\n                        <p>Where z = 1.22 + (0.80 × Entropy) + (-1.85 × KL Divergence) + (-1.32 × Overused Words/10) + (-3.03 × Suspicious Words) + (2.89 × Sentence Length Score)</p>          \n\n                        <div className=\"calculation-details\">\n                            <p>For this article:</p>\n                            <ul>\n                                <li><strong>Entropy:</strong> {entropyScore} × {weights.entropy} = {(entropyScore * weights.entropy).toFixed(2)}</li>\n                                <li><strong>KL Divergence:</strong> {klDivergence} × {weights.klDivergence} = {(klDivergence * weights.klDivergence).toFixed(2)}</li>\n                                <li><strong>Overused Words:</strong> {overusedWordsCount}/10 × {weights.overusedWords} = {(overusedWordsCount / 10 * weights.overusedWords).toFixed(2)}</li>\n                                <li><strong>Suspicious Words:</strong> {suspiciousWordsCount} × {weights.suspiciousWords} = {(suspiciousWordsCount * weights.suspiciousWords).toFixed(2)}</li>\n                                <li><strong>Sentence Length Score:</strong> {sentenceLengthScore.toFixed(2)} × {weights.sentenceLength} = {(sentenceLengthScore * weights.sentenceLength).toFixed(2)}</li>\n                            </ul>\n                            <p><strong>z = {logitScore.toFixed(2)}</strong></p>\n                            <p><strong>Reliability Probability = {probabilityPercentage}%</strong></p>\n                            \n                            <p><strong>Confidence Level:</strong> {confidencePercentage}% (based on the magnitude of z-score)</p>\n                        </div>\n                    </div>\n                    \n                    <div className=\"modal-footer\">\n                        <p>For more detailed analysis and interactive visualizations, please refer to the Analysis Summary tab.</p>\n                    </div>\n                </div>\n            </div>\n        </div>\n    );\n};\n\nexport default SummaryModal;"],"mappings":"AAAA,MAAO,CAAAA,KAAK,KAAM,OAAO,CAAC,OAAAC,GAAA,IAAAC,IAAA,CAAAC,IAAA,IAAAC,KAAA,yBAE1B,KAAM,CAAAC,YAAY,CAAGC,IAAA,EAAkC,KAAAC,qBAAA,CAAAC,sBAAA,CAAAC,sBAAA,CAAAC,sBAAA,IAAjC,CAAEC,MAAM,CAAEC,OAAO,CAAEC,OAAQ,CAAC,CAAAP,IAAA,CAC9C,GAAI,CAACK,MAAM,EAAI,CAACE,OAAO,CAAE,MAAO,KAAI,CAEpC,KAAM,CAAEC,WAAW,CAAEC,YAAY,CAAEC,YAAa,CAAC,CAAGH,OAAO,CAC3D,KAAM,CAAAI,kBAAkB,CAAG,EAAAV,qBAAA,CAAAM,OAAO,CAACK,mBAAmB,UAAAX,qBAAA,kBAAAC,sBAAA,CAA3BD,qBAAA,CAA6BY,aAAa,UAAAX,sBAAA,iBAA1CA,sBAAA,CAA4CY,MAAM,GAAI,CAAC,CAClF,KAAM,CAAAC,oBAAoB,CAAG,EAAAZ,sBAAA,CAAAI,OAAO,CAACK,mBAAmB,UAAAT,sBAAA,kBAAAC,sBAAA,CAA3BD,sBAAA,CAA6Ba,eAAe,UAAAZ,sBAAA,iBAA5CA,sBAAA,CAA8CU,MAAM,GAAI,CAAC,CAEtF;AACA,KAAM,CAAAG,iBAAiB,CAAGT,WAAW,CAACS,iBAAiB,CACvD,KAAM,CAAAC,mBAAmB,CAAGC,IAAI,CAACC,GAAG,CAACH,iBAAiB,CAAG,IAAI,CAAC,CAAG,EAAE,CAEnE;AACA;AACA,KAAM,CAAAI,SAAS,CAAG,QAAQ,CAC1B,KAAM,CAAAC,OAAO,CAAG,CACZC,OAAO,CAAE,QAAQ,CAAS;AAC1Bb,YAAY,CAAE,CAAC,QAAQ,CAAG;AAC1BG,aAAa,CAAE,CAAC,QAAQ,CAAE;AAC1BG,eAAe,CAAE,CAAC,QAAQ,CAAE;AAC5BQ,cAAc,CAAE,CAAC,QAAW;AAChC,CAAC,CAED,KAAM,CAAAC,UAAU,CAAGJ,SAAS,CAC3BC,OAAO,CAACC,OAAO,CAAGd,YAAa,CAC/Ba,OAAO,CAACZ,YAAY,CAAGA,YAAa,CACpCY,OAAO,CAACT,aAAa,CAAGF,kBAAkB,CAAG,EAAG,CAChDW,OAAO,CAACN,eAAe,CAAGD,oBAAqB,CAC/CO,OAAO,CAACE,cAAc,CAAGN,mBAAoB,CAE9C;AACA,KAAM,CAAAQ,sBAAsB,CAAG,CAAC,EAAI,CAAC,CAAGP,IAAI,CAACQ,GAAG,CAAC,CAACF,UAAU,CAAC,CAAC,CAC9D,KAAM,CAAAG,qBAAqB,CAAG,CAACF,sBAAsB,CAAG,GAAG,EAAEG,OAAO,CAAC,CAAC,CAAC,CAEvE;AACA,KAAM,CAAAC,QAAQ,CAAGX,IAAI,CAACC,GAAG,CAACK,UAAU,CAAC,CACrC,KAAM,CAAAM,UAAU,CAAGZ,IAAI,CAACa,GAAG,CAAC,IAAI,CAAE,GAAG,CAAG,GAAG,CAAGF,QAAQ,CAAC,CACvD,KAAM,CAAAG,oBAAoB,CAAG,CAACF,UAAU,CAAG,GAAG,EAAEF,OAAO,CAAC,CAAC,CAAC,CAE1D;AACA,KAAM,CAAAK,UAAU,CAAGT,UAAU,EAAI,CAAC,CAClC,KAAM,CAAAU,cAAc,CAAGD,UAAU,CAAG,iBAAiB,CAAG,wBAAwB,CAGhF,mBACItC,IAAA,QAAKwC,SAAS,CAAC,eAAe,CAAAC,QAAA,cAC1BvC,KAAA,QAAKsC,SAAS,CAAC,eAAe,CAAAC,QAAA,eAC1BvC,KAAA,QAAKsC,SAAS,CAAC,cAAc,CAAAC,QAAA,eACzBzC,IAAA,OAAAyC,QAAA,CAAI,cAAY,CAAI,CAAC,cACrBzC,IAAA,WAAQwC,SAAS,CAAC,WAAW,CAACE,OAAO,CAAEhC,OAAQ,CAAA+B,QAAA,CAAC,MAAC,CAAQ,CAAC,EACzD,CAAC,cAENvC,KAAA,QAAKsC,SAAS,CAAC,YAAY,CAAAC,QAAA,eACvBvC,KAAA,QAAKsC,SAAS,CAAC,iBAAiB,CAAAC,QAAA,eAC5BvC,KAAA,QAAKsC,SAAS,CAAC,aAAa,CAAAC,QAAA,eACxBzC,IAAA,OAAAyC,QAAA,CAAI,gBAAc,CAAI,CAAC,cACvBvC,KAAA,OAAAuC,QAAA,eACIvC,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,aAAW,CAAQ,CAAC,IAAC,CAAC7B,WAAW,CAAC+B,SAAS,EAAK,CAAC,cAC7DzC,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,eAAa,CAAQ,CAAC,IAAC,CAAC7B,WAAW,CAACgC,eAAe,EAAK,CAAC,cACrE1C,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,oBAAkB,CAAQ,CAAC,IAAC,CAAC,CAAC7B,WAAW,CAACgC,eAAe,CAAGhC,WAAW,CAAC+B,SAAS,EAAEV,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,cAC/G/B,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,iBAAe,CAAQ,CAAC,IAAC,CAAC7B,WAAW,CAACiC,aAAa,EAAK,CAAC,cACrE3C,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,uBAAqB,CAAQ,CAAC,IAAC,CAAC7B,WAAW,CAACS,iBAAiB,CAAC,QAAM,EAAI,CAAC,EACrF,CAAC,EACJ,CAAC,cAENnB,KAAA,QAAKsC,SAAS,CAAC,aAAa,CAAAC,QAAA,eACxBzC,IAAA,OAAAyC,QAAA,CAAI,oBAAkB,CAAI,CAAC,cAC3BvC,KAAA,OAAAuC,QAAA,eACIvC,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,kBAAgB,CAAQ,CAAC,IAAC,CAAC5B,YAAY,EAAK,CAAC,cACzDX,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,gBAAc,CAAQ,CAAC,IAAC,CAAC3B,YAAY,EAAK,CAAC,EACvD,CAAC,cACLd,IAAA,MAAGwC,SAAS,CAAC,oBAAoB,CAAAC,QAAA,CAAC,uMAGlC,CAAG,CAAC,EACH,CAAC,EACL,CAAC,cAENvC,KAAA,QAAKsC,SAAS,CAAC,4BAA4B,CAAAC,QAAA,eACvCzC,IAAA,OAAAyC,QAAA,CAAI,4BAA0B,CAAI,CAAC,cACnCzC,IAAA,MAAAyC,QAAA,CAAG,0GAAwG,CAAG,CAAC,cAC/GzC,IAAA,QAAKwC,SAAS,CAAC,SAAS,CAAAC,QAAA,cACpBvC,KAAA,SAAAuC,QAAA,EAAM,0BAAwB,cAAAzC,IAAA,QAAAyC,QAAA,CAAK,IAAE,CAAK,CAAC,IAAC,EAAM,CAAC,CAClD,CAAC,cACNzC,IAAA,MAAAyC,QAAA,CAAG,wKAAuJ,CAAG,CAAC,cAE9JvC,KAAA,QAAKsC,SAAS,CAAC,qBAAqB,CAAAC,QAAA,eAChCzC,IAAA,MAAAyC,QAAA,CAAG,mBAAiB,CAAG,CAAC,cACxBvC,KAAA,OAAAuC,QAAA,eACIvC,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,UAAQ,CAAQ,CAAC,IAAC,CAAC5B,YAAY,CAAC,QAAG,CAACa,OAAO,CAACC,OAAO,CAAC,KAAG,CAAC,CAACd,YAAY,CAAGa,OAAO,CAACC,OAAO,EAAEM,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,cACrH/B,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,gBAAc,CAAQ,CAAC,IAAC,CAAC3B,YAAY,CAAC,QAAG,CAACY,OAAO,CAACZ,YAAY,CAAC,KAAG,CAAC,CAACA,YAAY,CAAGY,OAAO,CAACZ,YAAY,EAAEmB,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,cACrI/B,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,iBAAe,CAAQ,CAAC,IAAC,CAAC1B,kBAAkB,CAAC,WAAM,CAACW,OAAO,CAACT,aAAa,CAAC,KAAG,CAAC,CAACF,kBAAkB,CAAG,EAAE,CAAGW,OAAO,CAACT,aAAa,EAAEgB,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,cAC5J/B,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,mBAAiB,CAAQ,CAAC,IAAC,CAACtB,oBAAoB,CAAC,QAAG,CAACO,OAAO,CAACN,eAAe,CAAC,KAAG,CAAC,CAACD,oBAAoB,CAAGO,OAAO,CAACN,eAAe,EAAEa,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,cAC9J/B,KAAA,OAAAuC,QAAA,eAAIzC,IAAA,WAAAyC,QAAA,CAAQ,wBAAsB,CAAQ,CAAC,IAAC,CAACnB,mBAAmB,CAACW,OAAO,CAAC,CAAC,CAAC,CAAC,QAAG,CAACP,OAAO,CAACE,cAAc,CAAC,KAAG,CAAC,CAACN,mBAAmB,CAAGI,OAAO,CAACE,cAAc,EAAEK,OAAO,CAAC,CAAC,CAAC,EAAK,CAAC,EAC1K,CAAC,cACLjC,IAAA,MAAAyC,QAAA,cAAGvC,KAAA,WAAAuC,QAAA,EAAQ,MAAI,CAACZ,UAAU,CAACI,OAAO,CAAC,CAAC,CAAC,EAAS,CAAC,CAAG,CAAC,cACnDjC,IAAA,MAAAyC,QAAA,cAAGvC,KAAA,WAAAuC,QAAA,EAAQ,4BAA0B,CAACT,qBAAqB,CAAC,GAAC,EAAQ,CAAC,CAAG,CAAC,cAE1E9B,KAAA,MAAAuC,QAAA,eAAGzC,IAAA,WAAAyC,QAAA,CAAQ,mBAAiB,CAAQ,CAAC,IAAC,CAACJ,oBAAoB,CAAC,uCAAqC,EAAG,CAAC,EACpG,CAAC,EACL,CAAC,cAENrC,IAAA,QAAKwC,SAAS,CAAC,cAAc,CAAAC,QAAA,cACzBzC,IAAA,MAAAyC,QAAA,CAAG,sGAAoG,CAAG,CAAC,CAC1G,CAAC,EACL,CAAC,EACL,CAAC,CACL,CAAC,CAEd,CAAC,CAED,cAAe,CAAAtC,YAAY","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}